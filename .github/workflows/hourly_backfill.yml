name: Hourly 10-Year Backfill

on:
  schedule:
    # JST 01:15 - 05:15, 08:15 - 23:15
    # JST 06:15 & 07:15 (UTC 21 & 22) は Daily Indices (JST 06:30) と重なるリスクがあるためスキップ
    - cron: '15 16-20,23,0-14 * * *'
  workflow_dispatch:
    inputs:
      debug_mode:
        description: 'Run valid check only'
        type: boolean
        default: false

jobs:
  backfill:
    runs-on: ubuntu-latest
    timeout-minutes: 60 # 1時間で強制終了（次のバッチに譲る）
    permissions:
      contents: write
    
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: 'recursive'
      
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
          
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Calculate Target Period
        id: calc
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          HF_REPO: ${{ vars.HF_REPO }}
          PYTHONPATH: data_engine
        run: |
          # 期間計算スクリプト実行
          OUTPUT=$(python data_engine/backfill_manager.py)
          
          if [[ "$OUTPUT" == *"FINISHED"* ]]; then
            echo "Backfill completed or limit reached."
            echo "finished=true" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # "START=YYYY-MM-DD" 形式で出力されるのでパース
          START=$(echo "$OUTPUT" | grep "START=" | cut -d'=' -f2)
          END=$(echo "$OUTPUT" | grep "END=" | cut -d'=' -f2)
          
          echo "Target Period: $START ~ $END"
          echo "start_date=$START" >> $GITHUB_OUTPUT
          echo "end_date=$END" >> $GITHUB_OUTPUT
          echo "finished=false" >> $GITHUB_OUTPUT

      - name: Execute Backfill (Main Engine)
        if: steps.calc.outputs.finished == 'false'
        env:
          EDINET_API_KEY: ${{ secrets.EDINET_API_KEY }}
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          HF_REPO: ${{ vars.HF_REPO }}
          PYTHONPATH: data_engine
        run: |
          # main.py を呼び出して取得・保存・カタログ登録
          # --mode worker としているが、単体実行なら merger 無しで完結するかは main.py 次第
          # Phase 3 の main.py は単体実行でもカタログDeltaを保存する設計。
          # Global Merge は日次バッチ（Merger）に任せるか、ここでやるか。
          # 整合性のため、ここでも Merger モードを最後に呼ぶのが安全。
          
          RUN_ID="backfill-${{ steps.calc.outputs.start_date }}"
          
          # 1. Fetch & Parse
          echo "Running worker..."
          # 全書類取得のためフィルタリングなし（main.pyのデフォルト挙動を確認済）
          python data_engine/main.py \
            --start "${{ steps.calc.outputs.start_date }}" \
            --end "${{ steps.calc.outputs.end_date }}" \
            --mode worker \
            --run-id "$RUN_ID" \
            --chunk-id "0"

          # 2. Merge (Catalog Update)
          echo "Running merger..."
          python data_engine/main.py --mode merger --run-id "$RUN_ID"

      - name: Update Cursor
        if: steps.calc.outputs.finished == 'false' && success()
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          HF_REPO: ${{ vars.HF_REPO }}
          PYTHONPATH: data_engine
        run: |
          # 成功したらカーソルを更新（完了した end_date を渡し、次は end_date + 1 から始める）
          python data_engine/backfill_manager.py --update-cursor "${{ steps.calc.outputs.end_date }}"
